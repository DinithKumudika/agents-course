# Qu'est-ce que l'Appel de Fonctions ?

L'appel de fonctions (*function-calling*) est une **façon pour un LLM de prendre des actions sur son environnement**. Il a d'abord été [introduit dans GPT-4](https://openai.com/index/function-calling-and-other-api-updates/), et a ensuite été reproduit dans d'autres modèles.

Tout comme les outils d'un Agent, l'appel de fonctions donne au modèle la capacité de **prendre une action sur son environnement**. Cependant, la capacité d'appel de fonctions **est apprise par le modèle**, et repose **moins sur le prompting que d'autres techniques d'agents**.

Durant l'Unité 1, l'Agent **n'a pas appris à utiliser les Outils**, nous avons juste fourni la liste, et nous nous sommes appuyés sur le fait que le modèle **était capable de généraliser sur la définition d'un plan utilisant ces Outils**. 

Alors qu'ici, **avec l'appel de fonctions, l'Agent est ajusté finement (entraîné) pour utiliser les Outils**.

## Comment le modèle "apprend-il" à prendre une action ?

Dans l'Unité 1, nous avons exploré le flux de travail général d'un agent. Une fois que l'utilisateur a donné quelques outils à l'agent et l'a sollicité avec une requête, le modèle va cycler à travers :

1. *Réfléchir* : Quelle(s) action(s) dois-je prendre pour atteindre l'objectif.
2. *Agir* : Formater l'action avec le bon paramètre et arrêter la génération.
3. *Observer* : Récupérer le résultat de l'exécution.

Dans une conversation "typique" avec un modèle via une API, la conversation alternera entre les messages utilisateur et assistant comme ceci :

```python
conversation = [
    {"role": "user", "content": "J'ai besoin d'aide avec ma commande"},
    {"role": "assistant", "content": "Je serais ravi de vous aider. Pourriez-vous fournir votre numéro de commande ?"},
    {"role": "user", "content": "C'est ORDER-123"},
]
```

L'appel de fonctions apporte **de nouveaux rôles à la conversation** ! 

1. Un nouveau rôle pour une **Action** 
2. Un nouveau rôle pour une **Observation** 

Si nous prenons l'[API Mistral](https://docs.mistral.ai/capabilities/function_calling/) comme exemple, cela ressemblerait à ceci :

```python
conversation = [
    {
        "role": "user",
        "content": "Quel est le statut de ma transaction T1001 ?"
    },
    {
        "role": "assistant",
        "content": "",
        "function_call": {
            "name": "retrieve_payment_status",
            "arguments": "{\"transaction_id\": \"T1001\"}"
        }
    },
    {
        "role": "tool",
        "name": "retrieve_payment_status",
        "content": "{\"status\": \"Paid\"}"
    },
    {
        "role": "assistant",
        "content": "Votre transaction T1001 a été payée avec succès."
    }
]
```

> ... Mais vous avez dit qu'il y a un nouveau rôle pour les appels de fonctions ?

**Oui et non**, dans ce cas et dans beaucoup d'autres APIs, le modèle formate l'action à prendre comme un message "assistant". Le template de chat représentera ensuite cela comme des **tokens spéciaux** pour l'appel de fonctions.

- `[AVAILABLE_TOOLS]` – Démarre la liste des outils disponibles  
- `[/AVAILABLE_TOOLS]` – Termine la liste des outils disponibles  
- `[TOOL_CALLS]` – Fait un appel à un outil (c'est-à-dire, prend une "Action")  
- `[TOOL_RESULTS]` – "Observe" le résultat de l'action  
- `[/TOOL_RESULTS]` – Fin de l'observation (c'est-à-dire, le modèle peut décoder à nouveau)

Nous reparlerons de l'appel de fonctions dans ce cours, mais si vous voulez approfondir, vous pouvez consulter [cette excellente section de documentation](https://docs.mistral.ai/capabilities/function_calling/).

---
Maintenant que nous avons appris ce qu'est l'appel de fonctions et comment il fonctionne, **ajoutons quelques capacités d'appel de fonctions à un modèle qui n'a pas encore ces capacités** : [google/gemma-2-2b-it](https://huggingface.co/google/gemma-2-2b-it), en ajoutant quelques nouveaux tokens spéciaux au modèle.

Pour pouvoir faire cela, **nous devons d'abord comprendre l'ajustement fin et LoRA**.